# **Hierarchical Retrieval-Augmented Generation (H-RAG) System**

## **Overview**
This repository contains a **Hierarchical Retrieval-Augmented Generation (H-RAG) system** designed to answer user queries by integrating a two-layer vector store, a language model, and, if needed, an internet search. The agent intelligently selects the best approach based on query relevance, offering accurate, context-aware responses.

### **Main Components**
1. **Hierarchical Vector Store** for retrieving relevant document chunks.
2. **Language Model Integration** (using Mistral) for answering general knowledge queries.
3. **Internet Search** for accessing up-to-date information not covered in the vector store or language model.

---

## **Project Structure**

- `app.py` - The main Streamlit application for user interaction.
- `Technical Challenge_LLM Engineer.pdf` - PDF outlining the technical requirements.
- `documents.pdf` - Sample document(s) used to create vector embeddings.
- `model.ipynb` - Notebook for model experimentation and analysis.
- `chunks.txt` - Stores document chunks for hierarchical retrieval.
- `hierarchical_vector_store.index` - FAISS index storing document embeddings for similarity search.
- `requirements.txt` - List of dependencies for setting up the environment.

---

## **Features**

### **1. Document Ingestion**
   - Processes multiple PDF files from a specified directory.
   - Divides document text into manageable chunks and generates embeddings.

### **2. Hierarchical Vector Store**
   - A two-layer hierarchical vector store system:
     - **Layer 1**: Stores keywords or summaries linked to the detailed documents in Layer 2.
     - **Layer 2**: Contains in-depth document content.
   - Utilizes FAISS for efficient similarity-based retrieval.

### **3. Intelligent Query Agent**
   - Determines the best approach to answer user queries:
     - Retrieves information from the hierarchical RAG system.
     - Uses Mistral model knowledge for general or unsupported questions.
     - Conducts an internet search for the latest information if needed.

---

## **Installation**

1. **Clone the repository:**

    ```bash
    git clone https://github.com/your_username/your_repo_name.git
    cd your_repo_name
    ```

2. **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

3. **Download Mistral Model Weights**  
   Follow the [Mistral documentation](https://mistral.ai/) for downloading and setting up Mistral locally.

---

## **Usage**

### **Step 1: Create Vector Store**
   - Use the notebook or script to process your documents and create the vector store:
   - Extracts, splits, and embeds text from the `documents.pdf` file in the specified directory.
   - Run this step with:

      ```bash
      python model.ipynb
      ```

### **Step 2: Run the Streamlit Application**
   - Launch the `app.py` application:

      ```bash
      streamlit run app.py
      ```

   - Input queries through the interface and receive answers generated by the H-RAG system.

---

## **Testing the Agent**

### **Evaluation Questions**
The following test questions evaluate the agent’s effectiveness and relevance in various scenarios:

1. **Definition Queries**: "What is the minimum effective tax rate?"
2. **Contextual Queries**: "Explain BEPS in Singapore."
3. **Comparative Analysis**: "How does Singapore’s tax policy compare to other regions?"
4. **Keyword-Based Queries**: "List the key provisions under Pillar Two of BEPS."
5. **General Knowledge**: "What is BEPS, and why is it important?"

These questions are intended to measure the agent's ability to provide accurate and relevant responses.

---

## **Code Overview**

### **1. `model.ipynb`**
   - Extracts text from `documents.pdf` and any other files in the directory.
   - Divides text into manageable chunks and embeds them using the Mistral model.
   - Stores embeddings in the hierarchical vector store (`hierarchical_vector_store.index`).

### **2. `app.py`**
   - Streamlit application for end-user queries.
   - Calls the agent to choose the best approach for answering queries.

---

## **Dependencies**

- **PyPDF2**: For reading PDFs.
- **FAISS**: For efficient vector storage and similarity search.
- **Mistral**: For embedding generation.
- **Streamlit**: For the user interface.
- **Ollama**: Python interface for model interactions.

Install all dependencies using the `requirements.txt` file.

---

## **Contributing**

Contributions are welcome! Feel free to submit pull requests or open issues to help improve this project.

---



---

## **Contact**

For questions or suggestions, please reach out to [Balaji](balajisakthivel2504@gmail.com).
